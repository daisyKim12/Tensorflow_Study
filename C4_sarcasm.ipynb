{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnrFLyGkzRMDA/Yy+fhS64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daisyKim12/Tensorflow_Study/blob/main/Lecture_C4_sarcasm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCmtzkeGPI2Q"
      },
      "source": [
        "# Category 4\n",
        "Text Classfication using RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcvEYUuhPb3f"
      },
      "source": [
        "# NLP QUESTION\n",
        "\n",
        "For this task you will build a classifier for the sarcasm dataset\n",
        "The classifier should have a final layer with 1 neuron activated by sigmoid as shown.  \n",
        "It will be tested against a number of sentences that the network hasn't previously seen. And you will be scored on whether sarcasm was correctly detected in those sentences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import"
      ],
      "metadata": {
        "id": "I3u7uBAQypaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "Bz3TBYtTy-og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
        "urllib.request.urlretrieve(url, 'sarcasm.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mv-BT_MzTe3",
        "outputId": "9333d423-9084-4ca0-f402-ec3a97e62b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('sarcasm.json', <http.client.HTTPMessage at 0x7867ee3ab2b0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "datas 변수에 json을 활용하여 로드"
      ],
      "metadata": {
        "id": "tW-io61fzfJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sarcasm.json') as f:\n",
        "  datas = json.load(f)"
      ],
      "metadata": {
        "id": "gt6e_qsPzuf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datas[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EphaXo5ez2hE",
        "outputId": "54729f07-a48a-4431-f70c-4211014ca13a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5',\n",
              "  'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              "  'is_sarcastic': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- X(=sentences) : headline\n",
        "- Y(=labels) : is_sarcastic"
      ],
      "metadata": {
        "id": "K5LW3e3Rz5Wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = list()\n",
        "labels = list()\n",
        "\n",
        "for data in datas:\n",
        "  sentences.append(data['headline'])\n",
        "  labels.append(data['is_sarcastic'])"
      ],
      "metadata": {
        "id": "sB378usP0Jti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzThyvzS0cP7",
        "outputId": "d78e75f1-5f17-4452-acb6-70b03de33407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"former versace store clerk sues over secret 'black code' for minority shoppers\",\n",
              " \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYRBVBug0mD4",
        "outputId": "03f88853-6d45-462a-99b0-edeffbdea7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_size = 20000\n",
        "\n",
        "train_sentences = sentences[:training_size]\n",
        "train_labels = labels[:training_size]\n",
        "\n",
        "validation_sentences = sentences[training_size:]\n",
        "validation_labels = labels[training_size:]"
      ],
      "metadata": {
        "id": "1VXXbzr-0w6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing using Tokenizer, pad_sequences"
      ],
      "metadata": {
        "id": "DeRw0NrB1j4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Tokenizer with options.\n",
        "* `num_words`: Number of tokenized number. The rest is treated as oov.\n",
        "* `oov_token`: Word not in Tokenizer is represented as `oov_teken`."
      ],
      "metadata": {
        "id": "DPBTuJgz7fO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1000\n",
        "oov_tok = \"<OOV>\""
      ],
      "metadata": {
        "id": "lP9mzeoV8B0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token = '<OOV>')"
      ],
      "metadata": {
        "id": "x05jWlZu8Ijr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWptwIFq-B9B"
      },
      "source": [
        "Using `fit_on_texts` to Tokenize sentence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(train_sentences)"
      ],
      "metadata": {
        "id": "2HP5RYwW8RUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in tokenizer.word_index.items():\n",
        "  print('{}  \\t======>\\t {}'.format(key, value))\n",
        "  if value == 25:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wubmnjO58Yo2",
        "outputId": "5c507fec-07d9-480e-eb31-7237ca4a1763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<OOV>  \t======>\t 1\n",
            "to  \t======>\t 2\n",
            "of  \t======>\t 3\n",
            "the  \t======>\t 4\n",
            "in  \t======>\t 5\n",
            "for  \t======>\t 6\n",
            "a  \t======>\t 7\n",
            "on  \t======>\t 8\n",
            "and  \t======>\t 9\n",
            "with  \t======>\t 10\n",
            "is  \t======>\t 11\n",
            "new  \t======>\t 12\n",
            "trump  \t======>\t 13\n",
            "man  \t======>\t 14\n",
            "from  \t======>\t 15\n",
            "at  \t======>\t 16\n",
            "about  \t======>\t 17\n",
            "you  \t======>\t 18\n",
            "by  \t======>\t 19\n",
            "this  \t======>\t 20\n",
            "after  \t======>\t 21\n",
            "be  \t======>\t 22\n",
            "up  \t======>\t 23\n",
            "out  \t======>\t 24\n",
            "that  \t======>\t 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsDxh2VL8j7X",
        "outputId": "301b4363-dcc8-4636-a5fe-2478dff76a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25637"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "word_index['trump']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-SHIBAY8qwt",
        "outputId": "ead74886-b447-4014-9655-fa498158bcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNqh5HgMAcKW"
      },
      "source": [
        "`texts_to_sequences`: Change Work into Numver\\\n",
        "__Caution__: `texts_to_sequences` must be applied seperatly to Train and Valid set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "validation_sequences = tokenizer.texts_to_sequences(validation_sentences)"
      ],
      "metadata": {
        "id": "XWVmFdoN81dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mnkb_HLR9VJd",
        "outputId": "029908e4-4489-4d7c-bc3f-721e959e688f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[328, 1, 799, 1, 1, 47, 389, 1, 1, 6, 1, 1],\n",
              " [4, 1, 1, 1, 23, 2, 161, 1, 390, 1, 6, 251, 9, 889],\n",
              " [153, 890, 2, 891, 1, 1, 595, 1, 221, 133, 36, 45, 2, 1],\n",
              " [1, 38, 213, 382, 2, 1, 29, 288, 23, 10, 1, 1, 1, 958],\n",
              " [715, 672, 1, 1, 1, 662, 553, 5, 4, 92, 1, 90]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `pad_sequences` to unify sentence length\n",
        "\n",
        "* `maxlen`: Maximum length. Any sentence longer than this will be cut off.\n",
        "* `truncating`: When cutting off overflow sentence, this option dicides rather to cut it from the begining or the end.\n",
        "* `padding`: When the sentence is shorter than `maxlen`, this option dicides rather to fill empty space from the begining or the end."
      ],
      "metadata": {
        "id": "Y6d1V8tp9ZBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'"
      ],
      "metadata": {
        "id": "pfz63qJc9nAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, truncating = trunc_type, padding = padding_type)\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "metadata": {
        "id": "9jQby35R9xaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2WR2jRe9-FN",
        "outputId": "964a2ba2-d405-48f1-8667-77c459cd1917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Caution__: When solving NPL label type is initially `list` type and must be changed into np.array to apply it into models."
      ],
      "metadata": {
        "id": "axN5p86k-V95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6F7y5sS-nI6",
        "outputId": "231c6ea1-f350-483b-a62e-25cb0010b25b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_labels)\n",
        "validation_labels = np.array(validation_labels)"
      ],
      "metadata": {
        "id": "qDBl_biK-tHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLFvkeFi-2ue",
        "outputId": "a8e147f0-3008-4a46-b5d9-77f250041350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modeling"
      ],
      "metadata": {
        "id": "wY3ql31r-rjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `Embedding layer` decrease the dimension of one-hot encoded data to solve `curse of dimension`."
      ],
      "metadata": {
        "id": "v2x4oZ66oibk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 16"
      ],
      "metadata": {
        "id": "sIjRio6XovWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "before decreasing dim"
      ],
      "metadata": {
        "id": "hHaeNv8ooxXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_padded[0]))\n",
        "sample = np.array(train_padded[0])\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-bWGS-zpScW",
        "outputId": "6ce88bb8-4a63-462d-cd55-ec06e70ba918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([328,   1, 799,   1,   1,  47, 389,   1,   1,   6,   1,   1,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after decreasing dim"
      ],
      "metadata": {
        "id": "3o5TLb-jPxao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Embedding(vocab_size, embedding_dim, input_length=max_length)\n",
        "x(sample)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO9MQpEDpkst",
        "outputId": "0d649984-e367-4104-816a-68aee547316a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16,), dtype=float32, numpy=\n",
              "array([ 0.00331431,  0.0097304 ,  0.0497132 ,  0.00566201,  0.04167168,\n",
              "        0.00473701, -0.04441952,  0.03080896,  0.01872296,  0.04903573,\n",
              "        0.00434301,  0.04594425,  0.00765662, -0.03595104,  0.01045061,\n",
              "        0.04806807], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])"
      ],
      "metadata": {
        "id": "kYd4bA6tpykp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfjDLRVKqXUu",
        "outputId": "6ccecc06-445f-473d-b795-d4343719d5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 120, 16)           16000     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 120, 128)         41472     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 128)              98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,961\n",
            "Trainable params: 160,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compile, Set Checkpoint, Fit, Load Weight"
      ],
      "metadata": {
        "id": "VIui-m_SqaKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "WK8tQqJmqhEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_AvlY0cIDXX"
      },
      "source": [
        "checkpoint_path = 'my_checkpoint.ckpt'\n",
        "checkpoint = ModelCheckpoint(checkpoint_path,\n",
        "                             save_weights_only=True,\n",
        "                             save_best_only=True,\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10"
      ],
      "metadata": {
        "id": "urgnMZjUq0N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byjJCmN_RpB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41204f45-19ba-420b-a4f6-b41e5edf1762"
      },
      "source": [
        "history = model.fit(train_padded, train_labels,\n",
        "                    validation_data=(validation_padded, validation_labels),\n",
        "                    callbacks=[checkpoint],\n",
        "                    epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.4480 - acc: 0.7737\n",
            "Epoch 1: val_loss improved from inf to 0.39601, saving model to my_checkpoint.ckpt\n",
            "625/625 [==============================] - 41s 45ms/step - loss: 0.4478 - acc: 0.7739 - val_loss: 0.3960 - val_acc: 0.8152\n",
            "Epoch 2/10\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.8335\n",
            "Epoch 2: val_loss improved from 0.39601 to 0.37820, saving model to my_checkpoint.ckpt\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3587 - acc: 0.8336 - val_loss: 0.3782 - val_acc: 0.8286\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3320 - acc: 0.8511\n",
            "Epoch 3: val_loss improved from 0.37820 to 0.37035, saving model to my_checkpoint.ckpt\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3320 - acc: 0.8511 - val_loss: 0.3704 - val_acc: 0.8298\n",
            "Epoch 4/10\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.3114 - acc: 0.8635\n",
            "Epoch 4: val_loss did not improve from 0.37035\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.3113 - acc: 0.8636 - val_loss: 0.3723 - val_acc: 0.8317\n",
            "Epoch 5/10\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.8700\n",
            "Epoch 5: val_loss improved from 0.37035 to 0.36798, saving model to my_checkpoint.ckpt\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.2972 - acc: 0.8701 - val_loss: 0.3680 - val_acc: 0.8347\n",
            "Epoch 6/10\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2865 - acc: 0.8760\n",
            "Epoch 6: val_loss did not improve from 0.36798\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.2864 - acc: 0.8759 - val_loss: 0.3704 - val_acc: 0.8332\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2766 - acc: 0.8819\n",
            "Epoch 7: val_loss did not improve from 0.36798\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.2766 - acc: 0.8819 - val_loss: 0.3919 - val_acc: 0.8262\n",
            "Epoch 8/10\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.8825\n",
            "Epoch 8: val_loss did not improve from 0.36798\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.2726 - acc: 0.8824 - val_loss: 0.4005 - val_acc: 0.8277\n",
            "Epoch 9/10\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.8858\n",
            "Epoch 9: val_loss did not improve from 0.36798\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.2658 - acc: 0.8857 - val_loss: 0.4017 - val_acc: 0.8250\n",
            "Epoch 10/10\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2588 - acc: 0.8895\n",
            "Epoch 10: val_loss did not improve from 0.36798\n",
            "625/625 [==============================] - 16s 25ms/step - loss: 0.2588 - acc: 0.8894 - val_loss: 0.4017 - val_acc: 0.8220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yReXnAa4rNz0",
        "outputId": "fefaae4f-61ca-4305-e239-fb01fd71af32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7866d8123df0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}
